{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(3, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "# compute ndcg@k (dcg@k / idcg@k) for a single sample\n",
    "def get_ndcg(r, ref, k):\n",
    "    dcg_max = dcg_at_k(ref, k)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    dcg = dcg_at_k(r, k)\n",
    "    return dcg / dcg_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read validation prediction from the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = read_json('valid_pred1.json')\n",
    "pred2 = read_json('valid_pred2.json')\n",
    "gt = read_json('/share/wulei/kdd-data/valid_answer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for the best threshold `t` to ensemble the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "t = 0\n",
    "for i in np.linspace(0, 1, 100):\n",
    "    pred = {}\n",
    "    for k in pred1.keys():\n",
    "        v1 = pred1[k]\n",
    "        v2 = pred2[k]\n",
    "        v1 = dict(v1)\n",
    "        v2 = dict(v2)\n",
    "        v = []\n",
    "        for kk in v1.keys():\n",
    "            v.append((kk, i * v1[kk] + (1 - i) * v2[kk]))\n",
    "    #     v = [(v2[i][0], v1[i][1] + v2[i][1]) for i in range(len(v1))]\n",
    "        v = sorted(v, key=lambda x: x[1], reverse=True)\n",
    "        pred[k] = v\n",
    "        \n",
    "    score = 0\n",
    "    k = 5\n",
    "    for key, val in gt.items():\n",
    "        ground_truth_ids = [str(x) for x in val]\n",
    "        predictions = [x[0] for x in pred[key][:k]]\n",
    "        ref_vec = [1.0] * len(ground_truth_ids)\n",
    "\n",
    "        pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions]\n",
    "        score += get_ndcg(pred_vec, ref_vec, k)\n",
    "        # print(key)\n",
    "        # print([pid for pid in predictions if pid not in ground_truth_ids])\n",
    "        # print('========')\n",
    "        # score += len(set(predictions).intersection(ground_truth_ids)) / len(ground_truth_ids)\n",
    "    score = score / len(gt)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        t = i\n",
    "        print('best score: %.4f, best t: %.4f' % (score, i))\n",
    "#     print('ndcg@%d: %.4f' % (k, score / len(gt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read testing prediction from the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = read_json('test_pred1.json')\n",
    "pred2 = read_json('test_pred3.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the ensembled score for the testing data and output submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {}\n",
    "for k in pred1.keys():\n",
    "    v1 = pred1[k]\n",
    "    v2 = pred2[k]\n",
    "    v1 = dict(v1)\n",
    "    v2 = dict(v2)\n",
    "    v = []\n",
    "    for kk in v1.keys():\n",
    "        v.append((kk, t * v1[kk] + (1 - t) * v2[kk]))\n",
    "#     v = [(v2[i][0], v1[i][1] + v2[i][1]) for i in range(len(v1))]\n",
    "    v = sorted(v, key=lambda x: x[1], reverse=True)\n",
    "    pred[k] = v\n",
    "\n",
    "submission = []\n",
    "for k, v in pred.items():\n",
    "    v = sorted(v, key=lambda x: x[1], reverse=True)\n",
    "    v = [x[0] for x in v]\n",
    "    submission.append([k] + v[:5])\n",
    "\n",
    "submission = pd.DataFrame(submission, columns=['query-id', 'product1', 'product2',\n",
    "                                               'product3', 'product4', 'product5'])\n",
    "submission.to_csv('./submissions/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
